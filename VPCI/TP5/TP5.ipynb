{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdb0d0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Si queremos que las imágenes sean mostradas en una ventana emergente quitar el inline\n",
    "# %matplotlib inline\n",
    "%matplotlib\n",
    "\n",
    "# Importamos las librerías necesarias\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc6bc374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x176c64023a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Puntero al video\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# Tomamos el primer frame del video (donde vamos a definir la ROI)\n",
    "#-----------------------------------------------------------------\n",
    "ret,frame = cap.read()\n",
    "frame = cv.cvtColor(frame,cv.COLOR_BGR2RGB)\n",
    "# Definimos la ubicación inical de la ventana de seguimiento\n",
    "#-----------------------------------------------------------\n",
    "# r,h,c,w - Región de la imagen (valores harcodeados)\n",
    "x, y, w, h = 248, 155, 120, 114\n",
    "track_window = (x, y, w, h)\n",
    "\n",
    "# Una vez definida la ROI recortamos esa parte de la imagen que utilizaremos para seguimiento\n",
    "#--------------------------------------------------------------------------------------------\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "# Pasamos la ROI a HSV (los valores de H son más estables a cambios de intensidad)\n",
    "hsv_roi =  cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
    "# Definimos una máscara para el histograma (Hue: 0..180, Saturation:60..255, Value:32..255)\n",
    "mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "# Y calculamos el histograma sobre esa máscara (toma solo el Hue: tonalidad)\n",
    "roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "# Normalizamos el histograma (entre 0 y 255 según indica el flag cv.NORM_MINMAX)\n",
    "cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n",
    "\n",
    "# Mostramos lo que se fue armando en relación a la ROI\n",
    "#-----------------------------------------------------\n",
    "plt.figure()\n",
    "plt.imshow(mask)\n",
    "\n",
    "# Muestro la imagen como para ver dónde definimos la ROI\n",
    "#-------------------------------------------------------\n",
    "plt.figure()\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "643cf90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condición de terminación: 10 iteraciones o moverse al menos 1pt\n",
    "#----------------------------------------------------------------\n",
    "term_crit = ( cv.TERM_CRITERIA_COUNT | cv.TERM_CRITERIA_EPS, 10, 1 )\n",
    "fourcc = cv.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv.VideoWriter('output.mp4', fourcc, 20.0, (640,480))\n",
    "while(cap.isOpened()):\n",
    "    # Tomamos un nuevo frame\n",
    "    #-----------------------\n",
    "    ret ,frame = cap.read()\n",
    "    # Mientras haya frames procesamos\n",
    "    #--------------------------------\n",
    "    if ret == True:\n",
    "        # Pasamos el nuevo frame a HSV\n",
    "        #-----------------------------\n",
    "        hsv = cv.cvtColor(frame, cv.COLOR_RGB2HSV)\n",
    "        \n",
    "        # Calculamos la proyección inversa del histograma\n",
    "        #------------------------------------------------\n",
    "        dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        # En términos probabilísticos, esto es la probabilidad que un píxel corresponda a los\n",
    "        # valores rescatados en el histograma de la imagen de testeo\n",
    "        # \"La retroproyección es una forma de registrar qué tan bien los píxeles de una imagen\n",
    "        # dada se ajustan a la distribución de píxeles en un modelo de histograma.\" \n",
    "        # Para la retroproyección, se calcula el modelo de histograma de una característica y \n",
    "        # luego se usa para encontrar esta característica en una imagen.\n",
    "        #\n",
    "        # NOTAR que busca en toda la imagen\n",
    "        #\n",
    "        # Un histograma de imagen mide la distribución de color (y brillo) de los píxeles en una\n",
    "        # imagen. Si se toma una imagen e se identifica una región de interés, por ejemplo una mano,\n",
    "        # y se calcula el histograma de los píxeles de ese objeto. Luego, se toma ese histograma y \n",
    "        # una segunda imagen y esencialmente se invierte el proceso: se elijen los píxeles en la \n",
    "        # segunda imagen que coincidan con el histograma de la primera. Es este proceso inverso el \n",
    "        # que le da el nombre de retroproyección. Luego se asume que las áreas de la imagen en la \n",
    "        # segunda imagen que tienen la misma distribución de color que un objeto en la primera imagen\n",
    "        # son una imagen del mismo (o similar) objeto.\n",
    "        \n",
    "        # Aplicamos meanshift para encontrar la nueva ubicación (precisa justamente que se le\n",
    "        # ingrese una retroproyección del histograma del objeto)\n",
    "        #-------------------------------------------------------\n",
    "        ret, track_window = cv.meanShift(dst, track_window, term_crit)\n",
    "        # La función implementa el algoritmo de búsqueda de objetos iterativos. Toma la \n",
    "        # retroproyección de entrada de un objeto y la posición inicial. Se calcula el \n",
    "        # centro de masa en la ventana de la imagen de retroproyección y el centro de la \n",
    "        # ventana de búsqueda se desplaza al centro de masa. El procedimiento se repite \n",
    "        # hasta que se completa el número especificado de iteraciones criterios.maxCount \n",
    "        # o hasta que el centro de la ventana se desplaza menos que criterios.epsilon.\n",
    "        #\n",
    "        # El tamaño o la orientación de la ventana de búsqueda no cambian durante la búsqueda\n",
    "        #\n",
    "        # NOTAR que se le pasa como parámetro la ventana de trackeo inicial\n",
    "        \n",
    "        # Dibujamos la ventana de seguimiento en la imagen\n",
    "        #-------------------------------------------------\n",
    "        x,y,w,h = track_window\n",
    "        img2 = cv.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n",
    "        out.write(img2)\n",
    "        cv.imshow('Seguimiento',img2)\n",
    "\n",
    "        k = cv.waitKey(60) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        else:\n",
    "            cv.imwrite(chr(k)+\".jpg\",img2)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "out.release()\n",
    "cv.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8936ec45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864eb984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
